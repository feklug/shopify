import requests
from collections import defaultdict

# Shopify-Zugangsdaten
SHOP = os.getenv("SHOPIFY_URL")
ACCESS_TOKEN = os.getenv("SHOPIFY_TOKEN")
api_version = "2024-01"
LOCATION_ID = "108058247432"
  
  
def get_all_products_graphql():
    url = f"https://{SHOP}/admin/api/2023-10/graphql.json"
    headers = {
        "X-Shopify-Access-Token": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    products = []
    has_next_page = True
    cursor = None
    
    while has_next_page:
        query = """
        {
          products(first: 100, after: %s) {
            edges {
              node {
                id
                title
                vendor
                handle
                createdAt
              }
              cursor
            }
            pageInfo {
              hasNextPage
            }
          }
        }
        """ % (f'"{cursor}"' if cursor else "null")

        response = requests.post(url, headers=headers, json={"query": query})
        response.raise_for_status()
        data = response.json()
        
        edges = data["data"]["products"]["edges"]
        for edge in edges:
            node = edge["node"]
            products.append({
                "id": node["id"],
                "title": node["title"],
                "vendor": node["vendor"],
                "handle": node["handle"],
                "createdAt": node["createdAt"]
            })
            cursor = edge["cursor"]
        
        has_next_page = data["data"]["products"]["pageInfo"]["hasNextPage"]
        print(f"üì¶ Geladene Produkte: {len(products)}")

    return products

def find_and_delete_duplicate_products():
    products = get_all_products_graphql()
    url = f"https://{SHOP}/admin/api/2023-10/graphql.json"
    headers = {
        "X-Shopify-Access-Token": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    # Gruppiere Produkte nach Titel
    products_by_title = defaultdict(list)
    for product in products:
        products_by_title[product["title"].strip().lower()].append(product)
    
    # Identifiziere Duplikate (mehr als ein Produkt mit gleichem Titel)
    duplicates = {title: items for title, items in products_by_title.items() if len(items) > 1}
    
    print(f"üîç Gefundene {len(duplicates)} Produkte mit Duplikaten")
    
    for title, duplicate_products in duplicates.items():
        # Sortiere nach Erstellungsdatum (√§ltestes zuerst)
        duplicate_products.sort(key=lambda x: x["createdAt"])
        
        # Behalte das neueste Produkt (letztes nach Sortierung)
        products_to_keep = duplicate_products[-1:]
        products_to_delete = duplicate_products[:-1]
        
        print(f"\nüîÑ Verarbeite Duplikate f√ºr: '{title}'")
        print(f"   Behalte: {products_to_keep[0]['id']} (Erstellt: {products_to_keep[0]['createdAt']})")
        
        for product in products_to_delete:
            mutation = """
            mutation {
              productDelete(input: {id: "%s"}) {
                deletedProductId
                userErrors {
                  field
                  message
                }
              }
            }
            """ % product["id"]

            response = requests.post(url, headers=headers, json={"query": mutation})
            response.raise_for_status()
            result = response.json()
            errors = result.get("data", {}).get("productDelete", {}).get("userErrors", [])
            
            if not errors:
                print(f"‚úÖ Gel√∂scht: {product['id']} (Erstellt: {product['createdAt']})")
            else:
                print(f"‚ùå Fehler beim L√∂schen: {product['id']} | Fehler: {errors}")

if __name__ == "__main__":
    find_and_delete_duplicate_products()
